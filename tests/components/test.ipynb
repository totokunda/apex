{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e9ba92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/Users/tosinkuye/apex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e26e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.preprocess.stepvideo.llm import Step1Model\n",
    "from src.quantize.load import load_gguf\n",
    "\n",
    "path = '/Users/tosinkuye/apex/step_llm.Q3_K.gguf'\n",
    "model_weights, _ = load_gguf(path, type='text_encoder', key_map='step')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b6c2323",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = 'transformer.layers.0.attention.wk.weight'\n",
    "print(model_weights[key].shape, model_weights[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3e2045",
   "metadata": {},
   "outputs": [],
   "source": [
    "from accelerate import init_empty_weights\n",
    "from transformers import PretrainedConfig\n",
    "import torch\n",
    "from src.quantize.dequant import dequantize_tensor\n",
    "from src.quantize.ggml_layer import patch_module\n",
    "\n",
    "\n",
    "model_path = '/Users/tosinkuye/apex-diffusion/components/stepfun-ai_stepvideo-t2v/step_llm'\n",
    "cfg = PretrainedConfig.from_pretrained(model_path)\n",
    "cfg.is_gguf = True\n",
    "with init_empty_weights():\n",
    "    model = Step1Model(cfg)\n",
    "\n",
    "patch_module(model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb248344",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor = model_weights[key]\n",
    "print(tensor.shape, tensor.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "52ef3194",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(model_weights, assign=True, strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "934e5d17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tok_embeddings.word_embeddings.weight torch.Size([65536, 6144]) cpu\n",
      "transformer.layers.0.attention.wq.weight torch.Size([6144, 2640]) meta\n",
      "transformer.layers.0.attention.wk.weight torch.Size([1024, 2640]) meta\n",
      "transformer.layers.0.attention.wv.weight torch.Size([1024, 4224]) meta\n",
      "transformer.layers.0.attention.wo.weight torch.Size([6144, 3456]) meta\n",
      "transformer.layers.0.feed_forward.ffn_gate.weight torch.Size([16896, 2640]) meta\n",
      "transformer.layers.0.feed_forward.ffn_up.weight torch.Size([16896, 2640]) meta\n",
      "transformer.layers.0.feed_forward.ffn_down.weight torch.Size([6144, 11616]) meta\n",
      "transformer.layers.0.feed_forward.ffn_down.temp.weight torch.Size([6144, 16896]) meta\n",
      "transformer.layers.0.attention_norm.weight torch.Size([6144]) cpu\n",
      "transformer.layers.0.ffn_norm.weight torch.Size([6144]) cpu\n",
      "transformer.layers.1.attention.wq.weight torch.Size([6144, 2640]) meta\n",
      "transformer.layers.1.attention.wk.weight torch.Size([1024, 2640]) meta\n",
      "transformer.layers.1.attention.wv.weight torch.Size([1024, 4224]) meta\n",
      "transformer.layers.1.attention.wo.weight torch.Size([6144, 3456]) meta\n",
      "transformer.layers.1.feed_forward.ffn_gate.weight torch.Size([16896, 2640]) meta\n",
      "transformer.layers.1.feed_forward.ffn_up.weight torch.Size([16896, 2640]) meta\n",
      "transformer.layers.1.feed_forward.ffn_down.weight torch.Size([6144, 11616]) meta\n",
      "transformer.layers.1.attention_norm.weight torch.Size([6144]) cpu\n",
      "transformer.layers.1.ffn_norm.weight torch.Size([6144]) cpu\n",
      "transformer.layers.2.attention.wq.weight torch.Size([6144, 2640]) meta\n",
      "transformer.layers.2.attention.wk.weight torch.Size([1024, 2640]) meta\n",
      "transformer.layers.2.attention.wv.weight torch.Size([1024, 3456]) meta\n",
      "transformer.layers.2.attention.wo.weight torch.Size([6144, 3456]) meta\n",
      "transformer.layers.2.feed_forward.ffn_gate.weight torch.Size([16896, 2640]) meta\n",
      "transformer.layers.2.feed_forward.ffn_up.weight torch.Size([16896, 2640]) meta\n",
      "transformer.layers.2.feed_forward.ffn_down.weight torch.Size([6144, 11616]) meta\n",
      "transformer.layers.2.attention_norm.weight torch.Size([6144]) cpu\n",
      "transformer.layers.2.ffn_norm.weight torch.Size([6144]) cpu\n",
      "transformer.layers.3.attention.wq.weight torch.Size([6144, 2640]) meta\n",
      "transformer.layers.3.attention.wk.weight torch.Size([1024, 2640]) meta\n",
      "transformer.layers.3.attention.wv.weight torch.Size([1024, 3456]) meta\n",
      "transformer.layers.3.attention.wo.weight torch.Size([6144, 3456]) meta\n",
      "transformer.layers.3.feed_forward.ffn_gate.weight torch.Size([16896, 2640]) meta\n",
      "transformer.layers.3.feed_forward.ffn_up.weight torch.Size([16896, 2640]) meta\n",
      "transformer.layers.3.feed_forward.ffn_down.weight torch.Size([6144, 9504]) meta\n",
      "transformer.layers.3.attention_norm.weight torch.Size([6144]) cpu\n",
      "transformer.layers.3.ffn_norm.weight torch.Size([6144]) cpu\n",
      "transformer.layers.4.attention.wq.weight torch.Size([6144, 2640]) meta\n",
      "transformer.layers.4.attention.wk.weight torch.Size([1024, 2640]) meta\n",
      "transformer.layers.4.attention.wv.weight torch.Size([1024, 3456]) meta\n",
      "transformer.layers.4.attention.wo.weight torch.Size([6144, 3456]) meta\n",
      "transformer.layers.4.feed_forward.ffn_gate.weight torch.Size([16896, 2640]) meta\n",
      "transformer.layers.4.feed_forward.ffn_up.weight torch.Size([16896, 2640]) meta\n",
      "transformer.layers.4.feed_forward.ffn_down.weight torch.Size([6144, 9504]) meta\n",
      "transformer.layers.4.attention_norm.weight torch.Size([6144]) cpu\n",
      "transformer.layers.4.ffn_norm.weight torch.Size([6144]) cpu\n",
      "transformer.layers.5.attention.wq.weight torch.Size([6144, 2640]) meta\n",
      "transformer.layers.5.attention.wk.weight torch.Size([1024, 2640]) meta\n",
      "transformer.layers.5.attention.wv.weight torch.Size([1024, 3456]) meta\n",
      "transformer.layers.5.attention.wo.weight torch.Size([6144, 3456]) meta\n",
      "transformer.layers.5.feed_forward.ffn_gate.weight torch.Size([16896, 2640]) meta\n",
      "transformer.layers.5.feed_forward.ffn_up.weight torch.Size([16896, 2640]) meta\n",
      "transformer.layers.5.feed_forward.ffn_down.weight torch.Size([6144, 9504]) meta\n",
      "transformer.layers.5.attention_norm.weight torch.Size([6144]) cpu\n",
      "transformer.layers.5.ffn_norm.weight torch.Size([6144]) cpu\n",
      "transformer.layers.6.attention.wq.weight torch.Size([6144, 2640]) meta\n",
      "transformer.layers.6.attention.wk.weight torch.Size([1024, 2640]) meta\n",
      "transformer.layers.6.attention.wv.weight torch.Size([1024, 3456]) meta\n",
      "transformer.layers.6.attention.wo.weight torch.Size([6144, 3456]) meta\n",
      "transformer.layers.6.feed_forward.ffn_gate.weight torch.Size([16896, 2640]) meta\n",
      "transformer.layers.6.feed_forward.ffn_up.weight torch.Size([16896, 2640]) meta\n",
      "transformer.layers.6.feed_forward.ffn_down.weight torch.Size([6144, 9504]) meta\n",
      "transformer.layers.6.attention_norm.weight torch.Size([6144]) cpu\n",
      "transformer.layers.6.ffn_norm.weight torch.Size([6144]) cpu\n",
      "transformer.layers.7.attention.wq.weight torch.Size([6144, 2640]) meta\n",
      "transformer.layers.7.attention.wk.weight torch.Size([1024, 2640]) meta\n",
      "transformer.layers.7.attention.wv.weight torch.Size([1024, 3456]) meta\n",
      "transformer.layers.7.attention.wo.weight torch.Size([6144, 3456]) meta\n",
      "transformer.layers.7.feed_forward.ffn_gate.weight torch.Size([16896, 2640]) meta\n",
      "transformer.layers.7.feed_forward.ffn_up.weight torch.Size([16896, 2640]) meta\n",
      "transformer.layers.7.feed_forward.ffn_down.weight torch.Size([6144, 9504]) meta\n",
      "transformer.layers.7.attention_norm.weight torch.Size([6144]) cpu\n",
      "transformer.layers.7.ffn_norm.weight torch.Size([6144]) cpu\n",
      "transformer.layers.8.attention.wq.weight torch.Size([6144, 2640]) meta\n",
      "transformer.layers.8.attention.wk.weight torch.Size([1024, 2640]) meta\n",
      "transformer.layers.8.attention.wv.weight torch.Size([1024, 3456]) meta\n",
      "transformer.layers.8.attention.wo.weight torch.Size([6144, 3456]) meta\n",
      "transformer.layers.8.feed_forward.ffn_gate.weight torch.Size([16896, 2640]) meta\n",
      "transformer.layers.8.feed_forward.ffn_up.weight torch.Size([16896, 2640]) meta\n",
      "transformer.layers.8.feed_forward.ffn_down.weight torch.Size([6144, 9504]) meta\n",
      "transformer.layers.8.attention_norm.weight torch.Size([6144]) cpu\n",
      "transformer.layers.8.ffn_norm.weight torch.Size([6144]) cpu\n",
      "transformer.layers.9.attention.wq.weight torch.Size([6144, 2640]) meta\n",
      "transformer.layers.9.attention.wk.weight torch.Size([1024, 2640]) meta\n",
      "transformer.layers.9.attention.wv.weight torch.Size([1024, 3456]) meta\n",
      "transformer.layers.9.attention.wo.weight torch.Size([6144, 3456]) meta\n",
      "transformer.layers.9.feed_forward.ffn_gate.weight torch.Size([16896, 2640]) meta\n",
      "transformer.layers.9.feed_forward.ffn_up.weight torch.Size([16896, 2640]) meta\n",
      "transformer.layers.9.feed_forward.ffn_down.weight torch.Size([6144, 9504]) meta\n",
      "transformer.layers.9.attention_norm.weight torch.Size([6144]) cpu\n",
      "transformer.layers.9.ffn_norm.weight torch.Size([6144]) cpu\n",
      "transformer.layers.10.attention.wq.weight torch.Size([6144, 2640]) meta\n",
      "transformer.layers.10.attention.wk.weight torch.Size([1024, 2640]) meta\n",
      "transformer.layers.10.attention.wv.weight torch.Size([1024, 3456]) meta\n",
      "transformer.layers.10.attention.wo.weight torch.Size([6144, 3456]) meta\n",
      "transformer.layers.10.feed_forward.ffn_gate.weight torch.Size([16896, 2640]) meta\n",
      "transformer.layers.10.feed_forward.ffn_up.weight torch.Size([16896, 2640]) meta\n",
      "transformer.layers.10.feed_forward.ffn_down.weight torch.Size([6144, 9504]) meta\n",
      "transformer.layers.10.attention_norm.weight torch.Size([6144]) cpu\n",
      "transformer.layers.10.ffn_norm.weight torch.Size([6144]) cpu\n",
      "transformer.layers.11.attention.wq.weight torch.Size([6144, 2640]) meta\n",
      "transformer.layers.11.attention.wk.weight torch.Size([1024, 2640]) meta\n",
      "transformer.layers.11.attention.wv.weight torch.Size([1024, 3456]) meta\n",
      "transformer.layers.11.attention.wo.weight torch.Size([6144, 3456]) meta\n",
      "transformer.layers.11.feed_forward.ffn_gate.weight torch.Size([16896, 2640]) meta\n",
      "transformer.layers.11.feed_forward.ffn_up.weight torch.Size([16896, 2640]) meta\n",
      "transformer.layers.11.feed_forward.ffn_down.weight torch.Size([6144, 9504]) meta\n",
      "transformer.layers.11.attention_norm.weight torch.Size([6144]) cpu\n",
      "transformer.layers.11.ffn_norm.weight torch.Size([6144]) cpu\n",
      "transformer.layers.12.attention.wq.weight torch.Size([6144, 2640]) meta\n",
      "transformer.layers.12.attention.wk.weight torch.Size([1024, 2640]) meta\n",
      "transformer.layers.12.attention.wv.weight torch.Size([1024, 3456]) meta\n",
      "transformer.layers.12.attention.wo.weight torch.Size([6144, 3456]) meta\n",
      "transformer.layers.12.feed_forward.ffn_gate.weight torch.Size([16896, 2640]) meta\n",
      "transformer.layers.12.feed_forward.ffn_up.weight torch.Size([16896, 2640]) meta\n",
      "transformer.layers.12.feed_forward.ffn_down.weight torch.Size([6144, 9504]) meta\n",
      "transformer.layers.12.attention_norm.weight torch.Size([6144]) cpu\n",
      "transformer.layers.12.ffn_norm.weight torch.Size([6144]) cpu\n",
      "transformer.layers.13.attention.wq.weight torch.Size([6144, 2640]) meta\n",
      "transformer.layers.13.attention.wk.weight torch.Size([1024, 2640]) meta\n",
      "transformer.layers.13.attention.wv.weight torch.Size([1024, 3456]) meta\n",
      "transformer.layers.13.attention.wo.weight torch.Size([6144, 3456]) meta\n",
      "transformer.layers.13.feed_forward.ffn_gate.weight torch.Size([16896, 2640]) meta\n",
      "transformer.layers.13.feed_forward.ffn_up.weight torch.Size([16896, 2640]) meta\n",
      "transformer.layers.13.feed_forward.ffn_down.weight torch.Size([6144, 9504]) meta\n",
      "transformer.layers.13.attention_norm.weight torch.Size([6144]) cpu\n",
      "transformer.layers.13.ffn_norm.weight torch.Size([6144]) cpu\n",
      "transformer.layers.14.attention.wq.weight torch.Size([6144, 2640]) meta\n",
      "transformer.layers.14.attention.wk.weight torch.Size([1024, 2640]) meta\n",
      "transformer.layers.14.attention.wv.weight torch.Size([1024, 3456]) meta\n",
      "transformer.layers.14.attention.wo.weight torch.Size([6144, 3456]) meta\n",
      "transformer.layers.14.feed_forward.ffn_gate.weight torch.Size([16896, 2640]) meta\n",
      "transformer.layers.14.feed_forward.ffn_up.weight torch.Size([16896, 2640]) meta\n",
      "transformer.layers.14.feed_forward.ffn_down.weight torch.Size([6144, 9504]) meta\n",
      "transformer.layers.14.attention_norm.weight torch.Size([6144]) cpu\n",
      "transformer.layers.14.ffn_norm.weight torch.Size([6144]) cpu\n",
      "transformer.layers.15.attention.wq.weight torch.Size([6144, 2640]) meta\n",
      "transformer.layers.15.attention.wk.weight torch.Size([1024, 2640]) meta\n",
      "transformer.layers.15.attention.wv.weight torch.Size([1024, 3456]) meta\n",
      "transformer.layers.15.attention.wo.weight torch.Size([6144, 3456]) meta\n",
      "transformer.layers.15.feed_forward.ffn_gate.weight torch.Size([16896, 2640]) meta\n",
      "transformer.layers.15.feed_forward.ffn_up.weight torch.Size([16896, 2640]) meta\n",
      "transformer.layers.15.feed_forward.ffn_down.weight torch.Size([6144, 9504]) meta\n",
      "transformer.layers.15.attention_norm.weight torch.Size([6144]) cpu\n",
      "transformer.layers.15.ffn_norm.weight torch.Size([6144]) cpu\n",
      "transformer.layers.16.attention.wq.weight torch.Size([6144, 2640]) meta\n",
      "transformer.layers.16.attention.wk.weight torch.Size([1024, 2640]) meta\n",
      "transformer.layers.16.attention.wv.weight torch.Size([1024, 3456]) meta\n",
      "transformer.layers.16.attention.wo.weight torch.Size([6144, 3456]) meta\n",
      "transformer.layers.16.feed_forward.ffn_gate.weight torch.Size([16896, 2640]) meta\n",
      "transformer.layers.16.feed_forward.ffn_up.weight torch.Size([16896, 2640]) meta\n",
      "transformer.layers.16.feed_forward.ffn_down.weight torch.Size([6144, 9504]) meta\n",
      "transformer.layers.16.attention_norm.weight torch.Size([6144]) cpu\n",
      "transformer.layers.16.ffn_norm.weight torch.Size([6144]) cpu\n",
      "transformer.layers.17.attention.wq.weight torch.Size([6144, 2640]) meta\n",
      "transformer.layers.17.attention.wk.weight torch.Size([1024, 2640]) meta\n",
      "transformer.layers.17.attention.wv.weight torch.Size([1024, 3456]) meta\n",
      "transformer.layers.17.attention.wo.weight torch.Size([6144, 3456]) meta\n",
      "transformer.layers.17.feed_forward.ffn_gate.weight torch.Size([16896, 2640]) meta\n",
      "transformer.layers.17.feed_forward.ffn_up.weight torch.Size([16896, 2640]) meta\n",
      "transformer.layers.17.feed_forward.ffn_down.weight torch.Size([6144, 9504]) meta\n",
      "transformer.layers.17.attention_norm.weight torch.Size([6144]) cpu\n",
      "transformer.layers.17.ffn_norm.weight torch.Size([6144]) cpu\n",
      "transformer.layers.18.attention.wq.weight torch.Size([6144, 2640]) meta\n",
      "transformer.layers.18.attention.wk.weight torch.Size([1024, 2640]) meta\n",
      "transformer.layers.18.attention.wv.weight torch.Size([1024, 3456]) meta\n",
      "transformer.layers.18.attention.wo.weight torch.Size([6144, 3456]) meta\n",
      "transformer.layers.18.feed_forward.ffn_gate.weight torch.Size([16896, 2640]) meta\n",
      "transformer.layers.18.feed_forward.ffn_up.weight torch.Size([16896, 2640]) meta\n",
      "transformer.layers.18.feed_forward.ffn_down.weight torch.Size([6144, 9504]) meta\n",
      "transformer.layers.18.attention_norm.weight torch.Size([6144]) cpu\n",
      "transformer.layers.18.ffn_norm.weight torch.Size([6144]) cpu\n",
      "transformer.layers.19.attention.wq.weight torch.Size([6144, 2640]) meta\n",
      "transformer.layers.19.attention.wk.weight torch.Size([1024, 2640]) meta\n",
      "transformer.layers.19.attention.wv.weight torch.Size([1024, 3456]) meta\n",
      "transformer.layers.19.attention.wo.weight torch.Size([6144, 3456]) meta\n",
      "transformer.layers.19.feed_forward.ffn_gate.weight torch.Size([16896, 2640]) meta\n",
      "transformer.layers.19.feed_forward.ffn_up.weight torch.Size([16896, 2640]) meta\n",
      "transformer.layers.19.feed_forward.ffn_down.weight torch.Size([6144, 9504]) meta\n",
      "transformer.layers.19.attention_norm.weight torch.Size([6144]) cpu\n",
      "transformer.layers.19.ffn_norm.weight torch.Size([6144]) cpu\n",
      "transformer.layers.20.attention.wq.weight torch.Size([6144, 2640]) meta\n",
      "transformer.layers.20.attention.wk.weight torch.Size([1024, 2640]) meta\n",
      "transformer.layers.20.attention.wv.weight torch.Size([1024, 3456]) meta\n",
      "transformer.layers.20.attention.wo.weight torch.Size([6144, 3456]) meta\n",
      "transformer.layers.20.feed_forward.ffn_gate.weight torch.Size([16896, 2640]) meta\n",
      "transformer.layers.20.feed_forward.ffn_up.weight torch.Size([16896, 2640]) meta\n",
      "transformer.layers.20.feed_forward.ffn_down.weight torch.Size([6144, 9504]) meta\n",
      "transformer.layers.20.attention_norm.weight torch.Size([6144]) cpu\n",
      "transformer.layers.20.ffn_norm.weight torch.Size([6144]) cpu\n",
      "transformer.layers.21.attention.wq.weight torch.Size([6144, 2640]) meta\n",
      "transformer.layers.21.attention.wk.weight torch.Size([1024, 2640]) meta\n",
      "transformer.layers.21.attention.wv.weight torch.Size([1024, 3456]) meta\n",
      "transformer.layers.21.attention.wo.weight torch.Size([6144, 3456]) meta\n",
      "transformer.layers.21.feed_forward.ffn_gate.weight torch.Size([16896, 2640]) meta\n",
      "transformer.layers.21.feed_forward.ffn_up.weight torch.Size([16896, 2640]) meta\n",
      "transformer.layers.21.feed_forward.ffn_down.weight torch.Size([6144, 9504]) meta\n",
      "transformer.layers.21.attention_norm.weight torch.Size([6144]) cpu\n",
      "transformer.layers.21.ffn_norm.weight torch.Size([6144]) cpu\n",
      "transformer.layers.22.attention.wq.weight torch.Size([6144, 2640]) meta\n",
      "transformer.layers.22.attention.wk.weight torch.Size([1024, 2640]) meta\n",
      "transformer.layers.22.attention.wv.weight torch.Size([1024, 3456]) meta\n",
      "transformer.layers.22.attention.wo.weight torch.Size([6144, 3456]) meta\n",
      "transformer.layers.22.feed_forward.ffn_gate.weight torch.Size([16896, 2640]) meta\n",
      "transformer.layers.22.feed_forward.ffn_up.weight torch.Size([16896, 2640]) meta\n",
      "transformer.layers.22.feed_forward.ffn_down.weight torch.Size([6144, 9504]) meta\n",
      "transformer.layers.22.attention_norm.weight torch.Size([6144]) cpu\n",
      "transformer.layers.22.ffn_norm.weight torch.Size([6144]) cpu\n",
      "transformer.layers.23.attention.wq.weight torch.Size([6144, 2640]) meta\n",
      "transformer.layers.23.attention.wk.weight torch.Size([1024, 2640]) meta\n",
      "transformer.layers.23.attention.wv.weight torch.Size([1024, 3456]) meta\n",
      "transformer.layers.23.attention.wo.weight torch.Size([6144, 3456]) meta\n",
      "transformer.layers.23.feed_forward.ffn_gate.weight torch.Size([16896, 2640]) meta\n",
      "transformer.layers.23.feed_forward.ffn_up.weight torch.Size([16896, 2640]) meta\n",
      "transformer.layers.23.feed_forward.ffn_down.weight torch.Size([6144, 9504]) meta\n",
      "transformer.layers.23.attention_norm.weight torch.Size([6144]) cpu\n",
      "transformer.layers.23.ffn_norm.weight torch.Size([6144]) cpu\n",
      "transformer.layers.24.attention.wq.weight torch.Size([6144, 2640]) meta\n",
      "transformer.layers.24.attention.wk.weight torch.Size([1024, 2640]) meta\n",
      "transformer.layers.24.attention.wv.weight torch.Size([1024, 3456]) meta\n",
      "transformer.layers.24.attention.wo.weight torch.Size([6144, 3456]) meta\n",
      "transformer.layers.24.feed_forward.ffn_gate.weight torch.Size([16896, 2640]) meta\n",
      "transformer.layers.24.feed_forward.ffn_up.weight torch.Size([16896, 2640]) meta\n",
      "transformer.layers.24.feed_forward.ffn_down.weight torch.Size([6144, 9504]) meta\n",
      "transformer.layers.24.attention_norm.weight torch.Size([6144]) cpu\n",
      "transformer.layers.24.ffn_norm.weight torch.Size([6144]) cpu\n",
      "transformer.layers.25.attention.wq.weight torch.Size([6144, 2640]) meta\n",
      "transformer.layers.25.attention.wk.weight torch.Size([1024, 2640]) meta\n",
      "transformer.layers.25.attention.wv.weight torch.Size([1024, 3456]) meta\n",
      "transformer.layers.25.attention.wo.weight torch.Size([6144, 3456]) meta\n",
      "transformer.layers.25.feed_forward.ffn_gate.weight torch.Size([16896, 2640]) meta\n",
      "transformer.layers.25.feed_forward.ffn_up.weight torch.Size([16896, 2640]) meta\n",
      "transformer.layers.25.feed_forward.ffn_down.weight torch.Size([6144, 9504]) meta\n",
      "transformer.layers.25.attention_norm.weight torch.Size([6144]) cpu\n",
      "transformer.layers.25.ffn_norm.weight torch.Size([6144]) cpu\n",
      "transformer.layers.26.attention.wq.weight torch.Size([6144, 2640]) meta\n",
      "transformer.layers.26.attention.wk.weight torch.Size([1024, 2640]) meta\n",
      "transformer.layers.26.attention.wv.weight torch.Size([1024, 3456]) meta\n",
      "transformer.layers.26.attention.wo.weight torch.Size([6144, 3456]) meta\n",
      "transformer.layers.26.feed_forward.ffn_gate.weight torch.Size([16896, 2640]) meta\n",
      "transformer.layers.26.feed_forward.ffn_up.weight torch.Size([16896, 2640]) meta\n",
      "transformer.layers.26.feed_forward.ffn_down.weight torch.Size([6144, 9504]) meta\n",
      "transformer.layers.26.attention_norm.weight torch.Size([6144]) cpu\n",
      "transformer.layers.26.ffn_norm.weight torch.Size([6144]) cpu\n",
      "transformer.layers.27.attention.wq.weight torch.Size([6144, 2640]) meta\n",
      "transformer.layers.27.attention.wk.weight torch.Size([1024, 2640]) meta\n",
      "transformer.layers.27.attention.wv.weight torch.Size([1024, 3456]) meta\n",
      "transformer.layers.27.attention.wo.weight torch.Size([6144, 3456]) meta\n",
      "transformer.layers.27.feed_forward.ffn_gate.weight torch.Size([16896, 2640]) meta\n",
      "transformer.layers.27.feed_forward.ffn_up.weight torch.Size([16896, 2640]) meta\n",
      "transformer.layers.27.feed_forward.ffn_down.weight torch.Size([6144, 9504]) meta\n",
      "transformer.layers.27.attention_norm.weight torch.Size([6144]) cpu\n",
      "transformer.layers.27.ffn_norm.weight torch.Size([6144]) cpu\n",
      "transformer.layers.28.attention.wq.weight torch.Size([6144, 2640]) meta\n",
      "transformer.layers.28.attention.wk.weight torch.Size([1024, 2640]) meta\n",
      "transformer.layers.28.attention.wv.weight torch.Size([1024, 3456]) meta\n",
      "transformer.layers.28.attention.wo.weight torch.Size([6144, 3456]) meta\n",
      "transformer.layers.28.feed_forward.ffn_gate.weight torch.Size([16896, 2640]) meta\n",
      "transformer.layers.28.feed_forward.ffn_up.weight torch.Size([16896, 2640]) meta\n",
      "transformer.layers.28.feed_forward.ffn_down.weight torch.Size([6144, 9504]) meta\n",
      "transformer.layers.28.attention_norm.weight torch.Size([6144]) cpu\n",
      "transformer.layers.28.ffn_norm.weight torch.Size([6144]) cpu\n",
      "transformer.layers.29.attention.wq.weight torch.Size([6144, 2640]) meta\n",
      "transformer.layers.29.attention.wk.weight torch.Size([1024, 2640]) meta\n",
      "transformer.layers.29.attention.wv.weight torch.Size([1024, 3456]) meta\n",
      "transformer.layers.29.attention.wo.weight torch.Size([6144, 3456]) meta\n",
      "transformer.layers.29.feed_forward.ffn_gate.weight torch.Size([16896, 2640]) meta\n",
      "transformer.layers.29.feed_forward.ffn_up.weight torch.Size([16896, 2640]) meta\n",
      "transformer.layers.29.feed_forward.ffn_down.weight torch.Size([6144, 9504]) meta\n",
      "transformer.layers.29.attention_norm.weight torch.Size([6144]) cpu\n",
      "transformer.layers.29.ffn_norm.weight torch.Size([6144]) cpu\n",
      "transformer.layers.30.attention.wq.weight torch.Size([6144, 2640]) meta\n",
      "transformer.layers.30.attention.wk.weight torch.Size([1024, 2640]) meta\n",
      "transformer.layers.30.attention.wv.weight torch.Size([1024, 3456]) meta\n",
      "transformer.layers.30.attention.wo.weight torch.Size([6144, 3456]) meta\n",
      "transformer.layers.30.feed_forward.ffn_gate.weight torch.Size([16896, 2640]) meta\n",
      "transformer.layers.30.feed_forward.ffn_up.weight torch.Size([16896, 2640]) meta\n",
      "transformer.layers.30.feed_forward.ffn_down.weight torch.Size([6144, 9504]) meta\n",
      "transformer.layers.30.attention_norm.weight torch.Size([6144]) cpu\n",
      "transformer.layers.30.ffn_norm.weight torch.Size([6144]) cpu\n",
      "transformer.layers.31.attention.wq.weight torch.Size([6144, 2640]) meta\n",
      "transformer.layers.31.attention.wk.weight torch.Size([1024, 2640]) meta\n",
      "transformer.layers.31.attention.wv.weight torch.Size([1024, 3456]) meta\n",
      "transformer.layers.31.attention.wo.weight torch.Size([6144, 3456]) meta\n",
      "transformer.layers.31.feed_forward.ffn_gate.weight torch.Size([16896, 2640]) meta\n",
      "transformer.layers.31.feed_forward.ffn_up.weight torch.Size([16896, 2640]) meta\n",
      "transformer.layers.31.feed_forward.ffn_down.weight torch.Size([6144, 9504]) meta\n",
      "transformer.layers.31.attention_norm.weight torch.Size([6144]) cpu\n",
      "transformer.layers.31.ffn_norm.weight torch.Size([6144]) cpu\n",
      "transformer.layers.32.attention.wq.weight torch.Size([6144, 2640]) meta\n",
      "transformer.layers.32.attention.wk.weight torch.Size([1024, 2640]) meta\n",
      "transformer.layers.32.attention.wv.weight torch.Size([1024, 3456]) meta\n",
      "transformer.layers.32.attention.wo.weight torch.Size([6144, 3456]) meta\n",
      "transformer.layers.32.feed_forward.ffn_gate.weight torch.Size([16896, 2640]) meta\n",
      "transformer.layers.32.feed_forward.ffn_up.weight torch.Size([16896, 2640]) meta\n",
      "transformer.layers.32.feed_forward.ffn_down.weight torch.Size([6144, 9504]) meta\n",
      "transformer.layers.32.attention_norm.weight torch.Size([6144]) cpu\n",
      "transformer.layers.32.ffn_norm.weight torch.Size([6144]) cpu\n",
      "transformer.layers.33.attention.wq.weight torch.Size([6144, 2640]) meta\n",
      "transformer.layers.33.attention.wk.weight torch.Size([1024, 2640]) meta\n",
      "transformer.layers.33.attention.wv.weight torch.Size([1024, 3456]) meta\n",
      "transformer.layers.33.attention.wo.weight torch.Size([6144, 3456]) meta\n",
      "transformer.layers.33.feed_forward.ffn_gate.weight torch.Size([16896, 2640]) meta\n",
      "transformer.layers.33.feed_forward.ffn_up.weight torch.Size([16896, 2640]) meta\n",
      "transformer.layers.33.feed_forward.ffn_down.weight torch.Size([6144, 9504]) meta\n",
      "transformer.layers.33.attention_norm.weight torch.Size([6144]) cpu\n",
      "transformer.layers.33.ffn_norm.weight torch.Size([6144]) cpu\n",
      "transformer.layers.34.attention.wq.weight torch.Size([6144, 2640]) meta\n",
      "transformer.layers.34.attention.wk.weight torch.Size([1024, 2640]) meta\n",
      "transformer.layers.34.attention.wv.weight torch.Size([1024, 3456]) meta\n",
      "transformer.layers.34.attention.wo.weight torch.Size([6144, 3456]) meta\n",
      "transformer.layers.34.feed_forward.ffn_gate.weight torch.Size([16896, 2640]) meta\n",
      "transformer.layers.34.feed_forward.ffn_up.weight torch.Size([16896, 2640]) meta\n",
      "transformer.layers.34.feed_forward.ffn_down.weight torch.Size([6144, 9504]) meta\n",
      "transformer.layers.34.attention_norm.weight torch.Size([6144]) cpu\n",
      "transformer.layers.34.ffn_norm.weight torch.Size([6144]) cpu\n",
      "transformer.layers.35.attention.wq.weight torch.Size([6144, 2640]) meta\n",
      "transformer.layers.35.attention.wk.weight torch.Size([1024, 2640]) meta\n",
      "transformer.layers.35.attention.wv.weight torch.Size([1024, 3456]) meta\n",
      "transformer.layers.35.attention.wo.weight torch.Size([6144, 3456]) meta\n",
      "transformer.layers.35.feed_forward.ffn_gate.weight torch.Size([16896, 2640]) meta\n",
      "transformer.layers.35.feed_forward.ffn_up.weight torch.Size([16896, 2640]) meta\n",
      "transformer.layers.35.feed_forward.ffn_down.weight torch.Size([6144, 9504]) meta\n",
      "transformer.layers.35.attention_norm.weight torch.Size([6144]) cpu\n",
      "transformer.layers.35.ffn_norm.weight torch.Size([6144]) cpu\n",
      "transformer.layers.36.attention.wq.weight torch.Size([6144, 2640]) meta\n",
      "transformer.layers.36.attention.wk.weight torch.Size([1024, 2640]) meta\n",
      "transformer.layers.36.attention.wv.weight torch.Size([1024, 3456]) meta\n",
      "transformer.layers.36.attention.wo.weight torch.Size([6144, 3456]) meta\n",
      "transformer.layers.36.feed_forward.ffn_gate.weight torch.Size([16896, 2640]) meta\n",
      "transformer.layers.36.feed_forward.ffn_up.weight torch.Size([16896, 2640]) meta\n",
      "transformer.layers.36.feed_forward.ffn_down.weight torch.Size([6144, 9504]) meta\n",
      "transformer.layers.36.attention_norm.weight torch.Size([6144]) cpu\n",
      "transformer.layers.36.ffn_norm.weight torch.Size([6144]) cpu\n",
      "transformer.layers.37.attention.wq.weight torch.Size([6144, 2640]) meta\n",
      "transformer.layers.37.attention.wk.weight torch.Size([1024, 2640]) meta\n",
      "transformer.layers.37.attention.wv.weight torch.Size([1024, 3456]) meta\n",
      "transformer.layers.37.attention.wo.weight torch.Size([6144, 3456]) meta\n",
      "transformer.layers.37.feed_forward.ffn_gate.weight torch.Size([16896, 2640]) meta\n",
      "transformer.layers.37.feed_forward.ffn_up.weight torch.Size([16896, 2640]) meta\n",
      "transformer.layers.37.feed_forward.ffn_down.weight torch.Size([6144, 9504]) meta\n",
      "transformer.layers.37.attention_norm.weight torch.Size([6144]) cpu\n",
      "transformer.layers.37.ffn_norm.weight torch.Size([6144]) cpu\n",
      "transformer.layers.38.attention.wq.weight torch.Size([6144, 2640]) meta\n",
      "transformer.layers.38.attention.wk.weight torch.Size([1024, 2640]) meta\n",
      "transformer.layers.38.attention.wv.weight torch.Size([1024, 3456]) meta\n",
      "transformer.layers.38.attention.wo.weight torch.Size([6144, 3456]) meta\n",
      "transformer.layers.38.feed_forward.ffn_gate.weight torch.Size([16896, 2640]) meta\n",
      "transformer.layers.38.feed_forward.ffn_up.weight torch.Size([16896, 2640]) meta\n",
      "transformer.layers.38.feed_forward.ffn_down.weight torch.Size([6144, 9504]) meta\n",
      "transformer.layers.38.attention_norm.weight torch.Size([6144]) cpu\n",
      "transformer.layers.38.ffn_norm.weight torch.Size([6144]) cpu\n",
      "transformer.layers.39.attention.wq.weight torch.Size([6144, 2640]) meta\n",
      "transformer.layers.39.attention.wk.weight torch.Size([1024, 2640]) meta\n",
      "transformer.layers.39.attention.wv.weight torch.Size([1024, 3456]) meta\n",
      "transformer.layers.39.attention.wo.weight torch.Size([6144, 3456]) meta\n",
      "transformer.layers.39.feed_forward.ffn_gate.weight torch.Size([16896, 2640]) meta\n",
      "transformer.layers.39.feed_forward.ffn_up.weight torch.Size([16896, 2640]) meta\n",
      "transformer.layers.39.feed_forward.ffn_down.weight torch.Size([6144, 9504]) meta\n",
      "transformer.layers.39.attention_norm.weight torch.Size([6144]) cpu\n",
      "transformer.layers.39.ffn_norm.weight torch.Size([6144]) cpu\n",
      "transformer.layers.40.attention.wq.weight torch.Size([6144, 2640]) meta\n",
      "transformer.layers.40.attention.wk.weight torch.Size([1024, 2640]) meta\n",
      "transformer.layers.40.attention.wv.weight torch.Size([1024, 3456]) meta\n",
      "transformer.layers.40.attention.wo.weight torch.Size([6144, 3456]) meta\n",
      "transformer.layers.40.feed_forward.ffn_gate.weight torch.Size([16896, 2640]) meta\n",
      "transformer.layers.40.feed_forward.ffn_up.weight torch.Size([16896, 2640]) meta\n",
      "transformer.layers.40.feed_forward.ffn_down.weight torch.Size([6144, 9504]) meta\n",
      "transformer.layers.40.attention_norm.weight torch.Size([6144]) cpu\n",
      "transformer.layers.40.ffn_norm.weight torch.Size([6144]) cpu\n",
      "transformer.layers.41.attention.wq.weight torch.Size([6144, 2640]) meta\n",
      "transformer.layers.41.attention.wk.weight torch.Size([1024, 2640]) meta\n",
      "transformer.layers.41.attention.wv.weight torch.Size([1024, 3456]) meta\n",
      "transformer.layers.41.attention.wo.weight torch.Size([6144, 3456]) meta\n",
      "transformer.layers.41.feed_forward.ffn_gate.weight torch.Size([16896, 2640]) meta\n",
      "transformer.layers.41.feed_forward.ffn_up.weight torch.Size([16896, 2640]) meta\n",
      "transformer.layers.41.feed_forward.ffn_down.weight torch.Size([6144, 9504]) meta\n",
      "transformer.layers.41.attention_norm.weight torch.Size([6144]) cpu\n",
      "transformer.layers.41.ffn_norm.weight torch.Size([6144]) cpu\n",
      "transformer.layers.42.attention.wq.weight torch.Size([6144, 2640]) meta\n",
      "transformer.layers.42.attention.wk.weight torch.Size([1024, 2640]) meta\n",
      "transformer.layers.42.attention.wv.weight torch.Size([1024, 3456]) meta\n",
      "transformer.layers.42.attention.wo.weight torch.Size([6144, 3456]) meta\n",
      "transformer.layers.42.feed_forward.ffn_gate.weight torch.Size([16896, 2640]) meta\n",
      "transformer.layers.42.feed_forward.ffn_up.weight torch.Size([16896, 2640]) meta\n",
      "transformer.layers.42.feed_forward.ffn_down.weight torch.Size([6144, 9504]) meta\n",
      "transformer.layers.42.attention_norm.weight torch.Size([6144]) cpu\n",
      "transformer.layers.42.ffn_norm.weight torch.Size([6144]) cpu\n",
      "transformer.layers.43.attention.wq.weight torch.Size([6144, 2640]) meta\n",
      "transformer.layers.43.attention.wk.weight torch.Size([1024, 2640]) meta\n",
      "transformer.layers.43.attention.wv.weight torch.Size([1024, 3456]) meta\n",
      "transformer.layers.43.attention.wo.weight torch.Size([6144, 3456]) meta\n",
      "transformer.layers.43.feed_forward.ffn_gate.weight torch.Size([16896, 2640]) meta\n",
      "transformer.layers.43.feed_forward.ffn_up.weight torch.Size([16896, 2640]) meta\n",
      "transformer.layers.43.feed_forward.ffn_down.weight torch.Size([6144, 9504]) meta\n",
      "transformer.layers.43.attention_norm.weight torch.Size([6144]) cpu\n",
      "transformer.layers.43.ffn_norm.weight torch.Size([6144]) cpu\n",
      "transformer.layers.44.attention.wq.weight torch.Size([6144, 2640]) meta\n",
      "transformer.layers.44.attention.wk.weight torch.Size([1024, 2640]) meta\n",
      "transformer.layers.44.attention.wv.weight torch.Size([1024, 3456]) meta\n",
      "transformer.layers.44.attention.wo.weight torch.Size([6144, 3456]) meta\n",
      "transformer.layers.44.feed_forward.ffn_gate.weight torch.Size([16896, 2640]) meta\n",
      "transformer.layers.44.feed_forward.ffn_up.weight torch.Size([16896, 2640]) meta\n",
      "transformer.layers.44.feed_forward.ffn_down.weight torch.Size([6144, 9504]) meta\n",
      "transformer.layers.44.attention_norm.weight torch.Size([6144]) cpu\n",
      "transformer.layers.44.ffn_norm.weight torch.Size([6144]) cpu\n",
      "transformer.layers.45.attention.wq.weight torch.Size([6144, 2640]) meta\n",
      "transformer.layers.45.attention.wk.weight torch.Size([1024, 2640]) meta\n",
      "transformer.layers.45.attention.wv.weight torch.Size([1024, 3456]) meta\n",
      "transformer.layers.45.attention.wo.weight torch.Size([6144, 3456]) meta\n",
      "transformer.layers.45.feed_forward.ffn_gate.weight torch.Size([16896, 2640]) meta\n",
      "transformer.layers.45.feed_forward.ffn_up.weight torch.Size([16896, 2640]) meta\n",
      "transformer.layers.45.feed_forward.ffn_down.weight torch.Size([6144, 9504]) meta\n",
      "transformer.layers.45.attention_norm.weight torch.Size([6144]) cpu\n",
      "transformer.layers.45.ffn_norm.weight torch.Size([6144]) cpu\n",
      "transformer.layers.46.attention.wq.weight torch.Size([6144, 2640]) meta\n",
      "transformer.layers.46.attention.wk.weight torch.Size([1024, 2640]) meta\n",
      "transformer.layers.46.attention.wv.weight torch.Size([1024, 3456]) meta\n",
      "transformer.layers.46.attention.wo.weight torch.Size([6144, 3456]) meta\n",
      "transformer.layers.46.feed_forward.ffn_gate.weight torch.Size([16896, 2640]) meta\n",
      "transformer.layers.46.feed_forward.ffn_up.weight torch.Size([16896, 2640]) meta\n",
      "transformer.layers.46.feed_forward.ffn_down.weight torch.Size([6144, 9504]) meta\n",
      "transformer.layers.46.attention_norm.weight torch.Size([6144]) cpu\n",
      "transformer.layers.46.ffn_norm.weight torch.Size([6144]) cpu\n",
      "transformer.layers.47.attention.wq.weight torch.Size([6144, 2640]) meta\n",
      "transformer.layers.47.attention.wk.weight torch.Size([1024, 2640]) meta\n",
      "transformer.layers.47.attention.wv.weight torch.Size([1024, 3456]) meta\n",
      "transformer.layers.47.attention.wo.weight torch.Size([6144, 3456]) meta\n",
      "transformer.layers.47.feed_forward.ffn_gate.weight torch.Size([16896, 2640]) meta\n",
      "transformer.layers.47.feed_forward.ffn_up.weight torch.Size([16896, 2640]) meta\n",
      "transformer.layers.47.feed_forward.ffn_down.weight torch.Size([6144, 9504]) meta\n",
      "transformer.layers.47.attention_norm.weight torch.Size([6144]) cpu\n",
      "transformer.layers.47.ffn_norm.weight torch.Size([6144]) cpu\n"
     ]
    }
   ],
   "source": [
    "for key, value in model.state_dict().items():\n",
    "    print(key, value.shape, value.device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "apex",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
