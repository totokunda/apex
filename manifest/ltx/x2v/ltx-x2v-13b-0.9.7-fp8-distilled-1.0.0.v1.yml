api_version: apex/v1
kind: Model
metadata:
  name: LTX X2V 13B 0.9.7 FP8 Distilled
  version: 1.0.0
  description: LTX X2V 13B 0.9.7 FP8 Distilled is a 13B parameter model for any-to-video
    generation.
  tags:
  - ltx
  - x2v
  - 13b
  - 0.9.7
  - fp8
  - distilled
spec:
  engine: ltx
  model_type:
  - t2v
  - i2v
  - control
  engine_type: torch
  denoise_type: base
  components:
  - type: text_encoder
    name: ltx/text_encoder
    base: T5EncoderModel
    model_path: PixArt-alpha/PixArt-XL-2-1024-MS/text_encoder
    config_path: https://huggingface.co/PixArt-alpha/PixArt-XL-2-1024-MS/resolve/main/text_encoder/config.json
    tokenizer_class: T5Tokenizer
    tokenizer_name: google/t5-v1_1-xxl
  - type: scheduler
    base: diffusers.FlowMatchEulerDiscreteScheduler
    config_path: https://huggingface.co/Lightricks/LTX-Video/resolve/main/scheduler/scheduler_config.json
  - type: vae
    base: ltx
    model_path: https://huggingface.co/Lightricks/LTX-Video/resolve/main/ltxv-13b-0.9.7-distilled-fp8.safetensors
    config_path: vae_configs/ltx/ltx_0.9.7.json
    converter_kwargs:
      version: 0.9.7
  - type: transformer
    base: ltx.base
    model_path: https://huggingface.co/Lightricks/LTX-Video/resolve/main/ltxv-13b-0.9.7-distilled-fp8.safetensors
    config_path: transformer_configs/ltx/ltx_x2v_13b.json
  defaults:
    run:
      num_inference_steps: 30
      guidance_scale: 5.0
      return_latents: true
      text_encoder_kwargs: {}
      guidance_rescale: 0.0
      offload: true
      render_on_step: false
  save:
    safe_serialization: true
    max_shard_size: 5GB
