api_version: apex/v1
kind: Model
metadata:
  name: Wan 2.1 14B ATI
  version: 1.0.0
  description: Wan 2.1 14B is a 14B parameter model for trajectory-to-video generation.
  tags:
  - wan
  - ati
  - 14b
  - '2.1'
spec:
  engine: wan
  model_type: ati
  engine_type: torch
  components:
  - type: scheduler
    base: src.scheduler.unipc.UniPCMultistepScheduler
    config:
      shift: 5.0
      use_dynamic_shifting: false
  - type: vae
    name: wan/vae
    base: wan
    model_path: Wan-AI/Wan2.1-I2V-14B-480P-Diffusers/vae
    config_path: https://huggingface.co/Wan-AI/Wan2.1-I2V-14B-480P-Diffusers/resolve/main/vae/config.json
  - type: text_encoder
    name: wan/text_encoder
    base: UMT5EncoderModel
    model_path: Wan-AI/Wan2.1-I2V-14B-480P-Diffusers/text_encoder
    config_path: https://huggingface.co/Wan-AI/Wan2.1-I2V-14B-480P-Diffusers/resolve/main/text_encoder/config.json
  - type: transformer
    base: wan.base
    model_path: bytedance-research/ATI
    config_path: https://huggingface.co/Wan-AI/Wan2.1-I2V-14B-480P-Diffusers/resolve/main/transformer/config.json
  - type: helper
    base: clip
    name: wan/clip
    model_path: Wan-AI/Wan2.1-I2V-14B-480P-Diffusers/image_encoder
    preprocessor_path: https://huggingface.co/Wan-AI/Wan2.1-I2V-14B-480P-Diffusers/resolve/main/image_processor/preprocessor_config.json
    processor_class: CLIPImageProcessor
    model_class: CLIPVisionModel
  - type: helper
    base: wan.ati
  defaults:
    run:
      num_inference_steps: 40
      guidance_scale: 5.0
      return_latents: false
      text_encoder_kwargs: {}
      attention_kwargs: {}
