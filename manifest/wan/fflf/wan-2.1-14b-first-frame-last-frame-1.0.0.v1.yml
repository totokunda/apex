api_version: apex/v1
kind: Model
metadata:
  name: Wan 2.1 14B First Frame Last Frame
  version: 1.0.0
  description: Wan 2.1 14B is a 14B parameter model for image-to-video generation.
  tags:
  - wan
  - fflf
  - 14b
  - '2.1'
  - 720p
spec:
  engine: wan
  model_type: fflf
  components:
  - type: scheduler
    base: diffusers.UniPCMultistepScheduler
    config_path: https://huggingface.co/Wan-AI/Wan2.1-FLF2V-14B-720P-diffusers/resolve/main/scheduler/scheduler_config.json
  - type: vae
    name: wan/vae_fflf
    base: wan
    model_path: Wan-AI/Wan2.1-FLF2V-14B-720P-diffusers/vae
    config_path: https://huggingface.co/Wan-AI/Wan2.1-FLF2V-14B-720P-diffusers/resolve/main/vae/config.json
  - type: text_encoder
    name: wan/text_encoder
    base: UMT5EncoderModel
    model_path: Wan-AI/Wan2.1-I2V-14B-480P-Diffusers/text_encoder
    config_path: https://huggingface.co/Wan-AI/Wan2.1-I2V-14B-480P-Diffusers/resolve/main/text_encoder/config.json
  - type: transformer
    base: wan.base
    model_path: Wan-AI/Wan2.1-FLF2V-14B-720P-diffusers/transformer
    config_path: https://huggingface.co/Wan-AI/Wan2.1-FLF2V-14B-720P-diffusers/resolve/main/transformer/config.json
  - type: helper
    base: clip
    name: wan/clip_fflf
    model_path: Wan-AI/Wan2.1-FLF2V-14B-720P-diffusers/image_encoder
    preprocessor_path: https://huggingface.co/Wan-AI/Wan2.1-FLF2V-14B-720P-diffusers/resolve/main/image_processor/preprocessor_config.json
    processor_class: CLIPImageProcessor
    model_class: CLIPVisionModel
  defaults:
    run:
      num_inference_steps: 30
      guidance_scale: 5.0
      return_latents: false
      text_encoder_kwargs: {}
      attention_kwargs: {}
