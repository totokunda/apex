api_version: apex/v1
kind: Model
metadata:
  name: Wan 2.2 A14B Image to Video
  version: 1.0.0
  description: Wan 2.2 A14B is a 14B parameter model for image-to-video generation.
  tags:
  - wan
  - i2v
  - 14b
  - '2.2'
spec:
  engine: wan
  model_type: i2v
  denoise_type: moe
  engine_type: torch
  components:
  - type: scheduler
    base: diffusers.UniPCMultistepScheduler
    config_path: https://huggingface.co/Wan-AI/Wan2.2-I2V-A14B-Diffusers/resolve/main/scheduler/scheduler_config.json
  - type: vae
    name: wan/vae_2.2
    base: wan
    model_path: Wan-AI/Wan2.2-I2V-A14B-Diffusers/vae
    config_path: https://huggingface.co/Wan-AI/Wan2.2-I2V-A14B-Diffusers/resolve/main/vae/config.json
  - type: text_encoder
    name: wan/text_encoder
    base: UMT5EncoderModel
    model_path: Wan-AI/Wan2.1-I2V-14B-480P-Diffusers/text_encoder
    config_path: https://huggingface.co/Wan-AI/Wan2.1-I2V-14B-480P-Diffusers/resolve/main/text_encoder/config.json
  - type: transformer
    name: transformer
    base: wan.base
    model_path: Wan-AI/Wan2.2-I2V-A14B-Diffusers/transformer
    config_path: https://huggingface.co/Wan-AI/Wan2.2-I2V-A14B-Diffusers/resolve/main/transformer/config.json
  - type: transformer
    name: transformer_2
    base: wan.base
    model_path: Wan-AI/Wan2.2-I2V-A14B-Diffusers/transformer_2
    config_path: https://huggingface.co/Wan-AI/Wan2.2-I2V-A14B-Diffusers/resolve/main/transformer_2/config.json
  - type: helper
    base: clip
    name: wan/clip
    model_path: Wan-AI/Wan2.1-I2V-14B-480P-Diffusers/image_encoder
    preprocessor_path: https://huggingface.co/Wan-AI/Wan2.1-I2V-14B-480P-Diffusers/resolve/main/image_processor/preprocessor_config.json
    processor_class: CLIPImageProcessor
    model_class: CLIPVisionModel
  defaults:
    run:
      num_inference_steps: 30
      boundary_ratio: 0.9
      expand_timesteps: false
      guidance_scale: 5.0
      return_latents: false
      text_encoder_kwargs: {}
      attention_kwargs: {}
