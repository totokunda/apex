name: wan_multitalk_14b
model_type: wan.multitalk
engine_type: wan
engine_model_type: multitalk
description: "WAN MultiTalk 14B model for audio-driven video generation"

# Model configuration
model_config:
  patch_size: [1, 2, 2]
  num_attention_heads: 32
  attention_head_dim: 128
  in_channels: 16
  out_channels: 16
  text_dim: 4096
  freq_dim: 256
  ffn_dim: 8192
  num_layers: 32
  cross_attn_norm: true
  qk_norm: "rms_norm_across_heads"
  eps: 1e-6
  image_dim: 1280
  added_kv_proj_dim: 1280
  rope_max_seq_len: 1024
  pos_embed_seq_len: 257
  # Audio-specific parameters
  audio_window: 5
  intermediate_dim: 512
  output_dim: 768
  context_tokens: 32
  vae_scale: 4
  norm_input_visual: true
  norm_output_audio: true

# Component configurations
text_encoder:
  name: t5
  path: google/t5-v1_1-xxl
  max_length: 512
  dtype: float16

vae:
  name: wan_vae
  path: wan_vae_weights
  dtype: float16

scheduler:
  name: euler
  params:
    num_train_timesteps: 1000
    beta_start: 0.0001
    beta_end: 0.02
    beta_schedule: "linear"

preprocessors:
  multitalk:
    name: wan.multitalk
    path: facebook/wav2vec2-base-960h
  clip:
    name: clip
    path: openai/clip-vit-large-patch14

# Training and inference settings
train_config:
  batch_size: 1
  learning_rate: 1e-4
  num_train_epochs: 100
  gradient_accumulation_steps: 8
  mixed_precision: fp16

inference_config:
  num_inference_steps: 40
  guidance_scale: 5.0
  audio_guidance_scale: 4.0
  height: 480
  width: 832
  num_frames: 81
  fps: 25 