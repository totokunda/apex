name: "Wan 2.1 14B Video Animation Control Editing"
description: "Wan 2.1 14B is a 14B parameter model for image-to-video generation."
engine: wan
type: vace

shared: []

components:
  - type: scheduler
    base: "diffusers.UniPCMultistepScheduler"
    config:
      flow_shift: 3.0
    config_path: "https://huggingface.co/Wan-AI/Wan2.1-VACE-14B-diffusers/resolve/main/scheduler/scheduler_config.json"

  - type: vae
    base: "wan" # one of cogvideo, hunyuan, ltx, mochi, stepvideo, wan 
    model_path: Wan-AI/Wan2.2-I2V-A14B-Diffusers/vae
    config_path: https://huggingface.co/Wan-AI/Wan2.2-I2V-A14B-Diffusers/resolve/main/vae/config.json

  - type: text_encoder
    name: "wan/text_encoder"
    base: "UMT5EncoderModel"
    model_path: Wan-AI/Wan2.1-I2V-14B-480P-Diffusers/text_encoder
    config_path: https://huggingface.co/Wan-AI/Wan2.1-I2V-14B-480P-Diffusers/resolve/main/text_encoder/config.json

  - type: transformer
    base: "wan.vace" 
    model_path:  https://huggingface.co/QuantStack/Wan2.1_T2V_14B_LightX2V_StepCfgDistill_VACE-GGUF/resolve/main/Wan2.1_T2V_14B_LightX2V_StepCfgDistill_VACE-Q8_0.gguf
    config_path: https://huggingface.co/Wan-AI/Wan2.1-VACE-14B-diffusers/resolve/main/transformer/config.json
    tag: "wan_vace_14b"


defaults:
  run:
    num_inference_steps: 30
    guidance_scale: 5.0
    return_latents: false
    text_encoder_kwargs: {}
    attention_kwargs: {}