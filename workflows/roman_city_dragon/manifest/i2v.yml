name: "Wan 2.2 A14B Image to Video"
description: "Wan 2.2 A14B is a 14B parameter model for image-to-video generation."
engine: wan
type: i2v
denoise_type: moe

shared: []

components:
  - type: scheduler
    base: "diffusers.UniPCMultistepScheduler"
    config_path: "https://huggingface.co/Wan-AI/Wan2.2-I2V-A14B-Diffusers/resolve/main/scheduler/scheduler_config.json"

  - type: vae
    base: "wan"
    model_path: /data/.hf_home/hub/models--Wan-AI--Wan2.1-VACE-14B-diffusers/snapshots/db79b90c60bbb45ceec9e41b9d5a4df934538ac4/vae

  - type: text_encoder
    name: "wan/text_encoder"
    base: "UMT5EncoderModel"
    model_path: /data/.hf_home/hub/models--Wan-AI--Wan2.1-VACE-14B-diffusers/snapshots/db79b90c60bbb45ceec9e41b9d5a4df934538ac4/text_encoder
    config_path: /data/.hf_home/hub/models--Wan-AI--Wan2.1-VACE-14B-diffusers/snapshots/db79b90c60bbb45ceec9e41b9d5a4df934538ac4/text_encoder/config.json

  
  - type: transformer
    name: "transformer"
    base: "wan.base" # one of cogvideo, hunyuan, ltx, mochi, stepvideo, wan 
    model_path: Wan-AI/Wan2.2-I2V-A14B-Diffusers/transformer
    config_path: https://huggingface.co/Wan-AI/Wan2.2-I2V-A14B-Diffusers/resolve/main/transformer/config.json
    tag: "wan_i2v_14b_22"

  - type: transformer
    name: "transformer_2"
    base: "wan.base" # one of cogvideo, hunyuan, ltx, mochi, stepvideo, wan 
    model_path: Wan-AI/Wan2.2-I2V-A14B-Diffusers/transformer_2
    config_path: https://huggingface.co/Wan-AI/Wan2.2-I2V-A14B-Diffusers/resolve/main/transformer_2/config.json
    tag: "wan_i2v_14b_22"

preprocessors: 
  - type: clip 
    name: "wan/clip"
    model_path: Wan-AI/Wan2.1-I2V-14B-480P-Diffusers/image_encoder
    preprocessor_path: https://huggingface.co/Wan-AI/Wan2.1-I2V-14B-480P-Diffusers/resolve/main/image_processor/preprocessor_config.json
    processor_class: CLIPImageProcessor
    model_class: CLIPVisionModel

defaults:
  run:
    num_inference_steps: 30
    boundary_ratio: 0.9
    expand_timesteps: false
    guidance_scale: 5.0
    return_latents: false
    text_encoder_kwargs: {}
    attention_kwargs: {}